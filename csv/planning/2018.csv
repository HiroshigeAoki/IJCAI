,title,track,categories,url,desc
0,"Model-free, Model-based, and General Intelligence",Invited Speakers,['Planning Algorithms'],https://www.ijcai.org/proceedings/2018/2,"During the 60s and 70s, AI researchers explored intuitions about intelligence by writing programs that displayed intelligent behavior. Many good ideas came out from this work  but  programs written by hand were not robust or general. After the 80s, research  increasingly shifted  to the development of learners capable of inferring  behavior and functions from experience and data, and solvers capable of tackling well-defined but intractable models like SAT, classical planning, Bayesian networks, and POMDPs. The learning approach has achieved considerable success but results in black boxes that do not have the flexibility, transparency, and generality of their model-based counterparts. Model-based approaches, on the other hand, require models and scalable algorithms. Model-free learners  and model-based solvers  have indeed close parallels with Systems 1 and 2 in current theories of the human mind: the first, a fast, opaque, and inflexible intuitive mind; the second,  a slow, transparent, and flexible analytical mind. In this paper, I review developments in AI and draw on these theories  to  discuss  the gap between model-free learners and model-based solvers, a gap that  needs to be bridged in order to have intelligent systems that are robust and general."
1,Managing Communication Costs under Temporal Uncertainty,Main,"['Search in Planning and Scheduling', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/12,"In multi-agent temporal planning, individual agents cannot know a priori when other agents will execute their actions and so treat those actions as uncertain. Only when others communicate the results of their actions is that uncertainty resolved. If a full communication protocol is specified ahead of time, then delay controllability can be used to assess the feasibility of the temporal plan. However, agents often have flexibility in choosing when to communicate the results of their action. In this paper, we address the question of how to choose communication protocols that guarantee the feasibility of the original temporal plan subject to some cost associated with that communication. To do so, we introduce a means of extracting delay controllability conflicts and show how we can use these conflicts to more efficiently guide our search. We then present three conflict-directed search algorithms and explore the theoretical and empirical trade-offs between the different approaches."
2,Solving Patrolling Problems in the Internet Environment,Main,"['Distributed;Multi-agent Planning', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/17,"We propose an algorithm for constructing efficient patrolling strategies in the Internet environment, where the protected targets are nodes connected to the network and the patrollers are software agents capable of detecting/preventing undesirable activities on the nodes. The algorithm is based on a novel compositional principle designed for a special class of strategies, and it can quickly construct (sub)optimal solutions even if the number of targets reaches hundreds of millions."
3,Multi-Agent Path Finding with Deadlines,Main,"['Planning Algorithms', 'Search in Planning and Scheduling', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/58,"We formalize Multi-Agent Path Finding with Deadlines (MAPF-DL). The objective is to maximize the number of agents that can reach their given goal vertices from their given start vertices within the deadline, without colliding with each other. We first show that MAPF-DL is NP-hard to solve optimally. We then present two classes of optimal algorithms, one based on a reduction of MAPF-DL to a flow problem and a subsequent compact integer linear programming formulation of the resulting reduced abstracted multi-commodity flow network and the other one based on novel combinatorial search algorithms. Our empirical results demonstrate that these MAPF-DL solvers scale well and each one dominates the other ones in different scenarios."
4,A Decentralised Approach to Intersection Traffic Management,Main,['Distributed;Multi-agent Planning'],https://www.ijcai.org/proceedings/2018/73,Traffic congestion has a significant impact on quality of life and the economy. This paper presents a decentralised traffic management mechanism for intersections using a distributed constraint optimisation approach (DCOP). Our solution outperforms the state of the art solution both for stable traffic conditions (about 60% reduced waiting time) and robustness to unpredictable events.
5,Extended Increasing Cost Tree Search for Non-Unit Cost Domains,Main,['Distributed;Multi-agent Planning'],https://www.ijcai.org/proceedings/2018/74,"Multi-agent pathfinding (MAPF) has applications in navigation, robotics, games and planning. Most work on search-based optimal algorithms for MAPF has focused on simple domains with unit cost actions and unit time steps. Although these constraints keep many aspects of the algorithms simple, they also severely limit the domains that can be used. In this paper we introduce a new definition of the MAPF problem for non-unit cost and non-unit time step domains along with new multiagent state successor generation schemes for these domains. Finally, we define an extended version of the increasing cost tree search algorithm (ICTS) for non-unit costs, with two new sub-optimal variants of ICTS: epsilon-ICTS and w-ICTS. Our experiments show that higher quality sub-optimal solutions are achievable in domains with finely discretized movement models in no more time than lower-quality, optimal solutions in domains with coarsely discretized movement models."
6,Meta-Level Control of Anytime Algorithms with Online Performance Prediction,Main,['Real-time Planning'],https://www.ijcai.org/proceedings/2018/208,"Anytime algorithms enable intelligent systems to trade computation time with solution quality. To exploit this crucial ability in real-time decision-making, the system must decide when to interrupt the anytime algorithm and act on the current solution. Existing meta-level control techniques, however, address this problem by relying on significant offline work that diminishes their practical utility and accuracy. We formally introduce an online performance prediction framework that enables meta-level control to adapt to each instance of a problem without any preprocessing. Using this framework, we then present a meta-level control technique and two stopping conditions. Finally, we show that our approach outperforms existing techniques that require substantial offline work. The result is efficient nonmyopic meta-level control that reduces the overhead and increases the benefits of using anytime algorithms in intelligent systems."
7,Open Loop Execution of Tree-Search Algorithms,Main,"['Planning Algorithms', 'Real-time Planning']",https://www.ijcai.org/proceedings/2018/327,"In the context of tree-search stochastic planning algorithms where a generative model is available, we consider on-line planning algorithms building trees in order to recommend an action. We investigate the question of avoiding re-planning in subsequent decision steps by directly using sub-trees as action recommender. Firstly, we propose a method for open loop control via a new algorithm taking the decision of re-planning or not at each time step based on an analysis of the statistics of the sub-tree. Secondly, we show that the probability of selecting a suboptimal action at any depth of the tree can be upper bounded and converges towards zero. Moreover, this upper bound decays in a logarithmic way between subsequent depths. This leads to a distinction between node-wise optimality and state-wise optimality. Finally, we empirically demonstrate that our method achieves a compromise between loss of performance and computational gain."
8,On Q-learning Convergence for Non-Markov Decision Processes,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2018/353,"Temporal-difference (TD) learning is an attractive, computationally efficient framework for model- free reinforcement learning. Q-learning is one of the most widely used TD learning technique that enables an agent to learn the optimal action-value function, i.e. Q-value function. Contrary to its widespread use, Q-learning has only been proven to converge on Markov Decision Processes (MDPs) and Q-uniform abstractions of finite-state MDPs. On the other hand, most real-world problems are inherently non-Markovian: the full true state of the environment is not revealed by recent observations. In this paper, we investigate the behavior of Q-learning when applied to non-MDP and non-ergodic domains which may have infinitely many underlying states. We prove that the convergence guarantee of Q-learning can be extended to a class of such non-MDP problems, in particular, to some non-stationary domains. We show that state-uniformity of the optimal Q-value function is a necessary and sufficient condition for Q-learning to converge even in the case of infinitely many internal states."
9,Extracting Action Sequences from Texts Based on Deep Reinforcement Learning,Main,"['Activity and Plan Recognition', 'Planning with Incomplete information']",https://www.ijcai.org/proceedings/2018/565,"Extracting action sequences from texts is challenging, as it  requires commonsense inferences based on world knowledge. Although there has been work on extracting action scripts, instructions, navigation actions, etc., they require either the set of candidate actions be provided in advance, or action descriptions are restricted to a specific form, e.g., description templates. In this paper we aim to extract action sequences from texts in \emph{free} natural language, i.e., without any restricted templates, provided the set of actions is unknown. We propose to extract action sequences from texts based on the deep reinforcement learning framework. Specifically, we view ``selecting'' or ``eliminating'' words from texts as ``actions'', and texts associated with actions as ``states''. We build Q-networks to learn policies of extracting actions and extract plans from the labeled texts. We demonstrate the effectiveness of our approach on several datasets with comparison to state-of-the-art approaches."
10,Multi-modal Predicate Identification using Dynamically Learned Robot Controllers,Main,"['POMDPs', 'Robot Planning']",https://www.ijcai.org/proceedings/2018/645,"Intelligent robots frequently need to explore the objects in their working environments. Modern sensors have enabled robots to learn object properties via perception of multiple modalities. However, object exploration in the real world poses a challenging trade-off between information gains and exploration action costs. Mixed observability Markov decision process (MOMDP) is a framework for planning under uncertainty, while accounting for both fully and partially observable components of the state. Robot perception frequently has to face such mixed observability. This work enables a robot equipped with an arm to dynamically construct query-oriented MOMDPs for multi-modal predicate identification (MPI) of objects. The robot's behavioral policy is learned from two datasets collected using real robots. Our approach enables a robot to explore object properties in a way that is significantly faster while improving accuracies in comparison to existing methods that rely on hand-coded exploration strategies."
11,Scheduling under Uncertainty: A Query-based Approach,Main,"['Scheduling', 'Planning with Incomplete information']",https://www.ijcai.org/proceedings/2018/646,"We consider a single machine, a set of unit-time jobs, and a set of unit-time errors. We assume that the time-slot at which each error will occur is not known in advance but, for every error, there exists an uncertainty area during which the error will take place. In order to find if the error occurs in a specific time-slot, it is necessary to issue a query to it. In this work, we study two problems: (i) the error-query scheduling problem, whose aim is to reveal enough error-free slots with the minimum number of queries, and (ii) the lexicographic error-query scheduling problem where we seek the earliest error-free slots with the minimum number of queries. We consider both the off-line and the on-line versions of the above problems. In the former, the whole instance and its characteristics are known in advance and we give a polynomial-time algorithm for the error-query scheduling problem. In the latter, the adversary has the power to decide, in an on-line way, the time-slot of appearance for each error. We propose then both lower bounds and algorithms whose competitive ratios asymptotically match these lower bounds."
12,Novel Structural Parameters for Acyclic Planning Using Tree Embeddings,Main,"['Planning Algorithms', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2018/647,"We introduce two novel structural parameters for acyclic planning (planning restricted to instances with acyclic causal graphs): up-depth and down-depth.  We show that cost-optimal acyclic planning restricted to instances with bounded domain size and bounded up- or down-depth can be solved in polynomial time.  For example, many of the tractable subclasses based on polytrees are covered by our result.  We analyze the parameterized complexity of planning with bounded up- and down-depth: in a certain sense, down-depth has better computational properties than up-depth.  Finally, we show that computing up- and down-depth are fixed-parameter tractable problems, just as many other structural parameters that are used in computer science.  We view our results as a natural step towards understanding the complexity of acyclic planning with bounded treewidth and other parameters."
13,Variable-Delay Controllability,Main,"['Planning under Uncertainty', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/648,"In temporal planning, agents must schedule a set of events satisfying a set of predetermined constraints. These scheduling problems become more difficult when the duration of certain actions are outside the agent's control. Delay controllability is the generalized notion of whether a schedule can be constructed in the face of uncertainty if the agent eventually learns when events occur. Our work introduces the substantially more complex setting of determining variable-delay controllability, where an agent learns about events after some unknown but bounded amount of time has passed. We provide an efficient O(n^3) variable-delay controllability checker and show how to create an execution strategy for variable-delay controllability problems. To our knowledge, these essential capabilities are absent from existing controllability checking algorithms. We conclude by providing empirical evaluations of the quality of variable-delay controllability results as compared to approximations that use fixed delays to model the same problems."
14,"Features, Projections, and Representation Change for Generalized Planning",Main,"['Planning Algorithms', 'Other approaches to planning', 'Conformant;Contingent  planning']",https://www.ijcai.org/proceedings/2018/649,"Generalized planning is concerned with the characterization and computation of plans that solve many instances at once. In the standard formulation, a generalized plan is a mapping from fea- ture or observation histories into actions, assuming that the instances share a common pool of features and actions. This assumption, however, excludes the standard relational planning domains where actions and objects change across instances. In this work, we extend the standard formulation of generalized planning to such domains. This is achieved by projecting the actions over the features, resulting in a common set of abstract actions which can be tested for soundness and completeness, and which can be used for generating general policies such as “if the gripper is empty, pick the clear block above x and place it on the table” that achieve the goal clear(x) in any Blocksworld instance. In this policy, “pick the clear block above x” is an abstract action that may represent the action Unstack(a, b) in one situation and the action Unstack(b, c) in another. Transformations are also introduced for computing such policies by means of fully observable non-deterministic (FOND) planners. The value of generalized representations for learning general policies is also discussed."
15,Planning and Learning with Stochastic Action Sets,Main,"['Markov Decisions Processes', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2018/650,"In many practical uses of reinforcement learning (RL) the set of actions available at a given state is a random variable, with realizations governed by an exogenous stochastic process. Somewhat surprisingly, the foundations for such sequential decision processes have been unaddressed. In this work, we formalize and investigate MDPs with stochastic action sets (SAS-MDPs) to provide these foundations. We show that optimal policies and value functions in this model have a structure that admits a compact representation. From an RL perspective, we show that Q-learning with sampled action sets is sound. In model-based settings, we consider two important special cases: when individual actions are available with independent probabilities, and a sampling-based model for unknown distributions. We develop polynomial-time value and policy iteration methods for both cases, and provide a polynomial-time linear programming solution for the first case."
16,LTL Realizability via Safety and Reachability Games,Main,"['Applications of Planning', 'Planning under Uncertainty', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/651,"In this paper, we address the problem of LTL realizability and synthesis. State of the art techniques rely on so-called bounded synthesis methods, which reduce the problem to a safety game. Realizability is determined by solving synthesis in a dual game. We provide a unified view of duality, and introduce novel bounded realizability methods via reductions to reachability games. Further, we introduce algorithms, based on AI automated planning, to solve these safety and reachability games. This is the the first complete approach to LTL realizability and synthesis via automated planning. Experiments illustrate that reductions to reachability games are an alternative to reductions to safety games, and show that planning can be a competitive approach to LTL realizability and synthesis."
17,Expectation Optimization with Probabilistic Guarantees in POMDPs with Discounted-Sum Objectives,Main,"['POMDPs', 'Theoretical Foundations of Planning', 'Planning under Uncertainty', 'Planning with Incomplete information']",https://www.ijcai.org/proceedings/2018/652,"Partially-observable Markov decision processes (POMDPs) with discounted-sum payoff are a standard framework to model a wide range of problems related to decision making under uncertainty. Traditionally, the goal has been to obtain policies that optimize the expectation of the discounted-sum payoff. A key drawback of the expectation measure is that even low probability events with extreme payoff can significantly affect the expectation, and thus the obtained policies are not necessarily risk averse. An alternate approach is to optimize the probability that the payoff is above a certain threshold, which allows to obtain risk-averse policies, but ignore optimization of the expectation. We consider the expectation optimization with probabilistic guarantee (EOPG) problem where the goal is to optimize the expectation ensuring that the payoff is above a given threshold with at least a specified probability. We present several results on the EOPG problem, including the first algorithm to solve it."
18,Computational Approaches for Stochastic Shortest Path on Succinct MDPs,Main,"['Markov Decisions Processes', 'Theoretical Foundations of Planning', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2018/653,"We consider the stochastic shortest path (SSP) problem for succinct Markov decision processes (MDPs), where the MDP consists of a set of variables, and a set of nondeterministic rules that update the variables. First, we show that several examples from the AI literature can be modeled as succinct MDPs. Then we present computational approaches for upper and lower bounds for the SSP problem: (a) for computing upper bounds, our method is polynomial-time in the implicit description of the MDP; (b) for lower bounds, we present a polynomial-time (in the size of the implicit description) reduction to quadratic programming. Our approach is applicable even to infinite-state MDPs. Finally, we present experimental results to demonstrate the effectiveness of our approach on several classical examples from the AI literature."
19,"Local Minima, Heavy Tails, and Search Effort for GBFS",Main,"['Planning Algorithms', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/654,"Problem difficulty for greedy best first search (GBFS) is not entirely understood, though existing work points to deep local minima and poor correlation between the h-values and the distance to goal as factors that have significant negative effect on the search effort. In this work, we show that there is a very strong exponential correlation between the depth of the single deepest local minima encountered in a search and the overall search effort. Furthermore, we find that the distribution of local minima depth changes dramatically based on the constrainedness of problems, suggesting an explanation for the previously observed heavy-tailed behavior in GBFS. In combinatorial search, a similar result led to the use of randomized restarts to escape deep subtrees with no solution and corresponding significant speed-ups. We adapt this method and propose a randomized restarting GBFS variant that improves GBFS performance by escaping deep local minima, and does so even in the presence of other, randomization-based, search enhancements."
20,Analyzing Tie-Breaking Strategies for the A* Algorithm,Main,"['Theoretical Foundations of Planning', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/655,"For a given state space and admissible heuristic function h there is always a tie-breaking strategy for which A* expands the minimum number of states [Dechter and Pearl, 1985]. We say that these strategies have optimal expansion. Although such a strategy always exists it may depend on the instance, and we currently do not know a tie-breaker that always guarantees optimal expansion. In this paper, we study tie-breaking strategies for A*. We analyze common strategies from the literature and prove that they do not have optimal expansion. We propose a novel tie-breaking strategy using cost adaptation that has always optimal expansion. We experimentally analyze the performance of A* using several tie-breaking strategies on domains from the IPC and zero-cost domains. Our best strategy solves significantly more instances than the standard method in the literature and more than the previous state-of-the-art strategy. Our analysis improves the understanding of how to develop effective tie-breaking strategies and our results also improve the state-of-the-art of tie-breaking strategies for A*."
21,Emergency Response Optimization using Online Hybrid Planning,Main,"['Planning Algorithms', 'Applications of Planning']",https://www.ijcai.org/proceedings/2018/656,"This paper poses the planning problem faced by the dispatcher responding to urban emergencies as a Hybrid (Discrete and Continuous) State and Action Markov Decision Process (HSA-MDP). We evaluate the performance of three online planning algorithms based on hindsight optimization for HSA- MDPs on real-world emergency data in the city of Corvallis, USA. The approach takes into account and respects the policy constraints imposed by the emergency department. We show that our algorithms outperform a heuristic policy commonly used by dispatchers by significantly reducing the average response time as well as lowering the fraction of unanswered calls. Our results give new insights into the problem such as withholding of resources for future emergencies in some situations."
22,Automata-Theoretic Foundations of FOND Planning for LTLf and LDLf Goals,Main,['Theoretical Foundations of Planning'],https://www.ijcai.org/proceedings/2018/657,"We study planning for LTLf and LDLf temporally extended goals in nondeterministic fully observable domains (FOND). We consider both strong and strong cyclic plans, and develop foundational automata-based techniques to deal with both cases.  Using these techniques we provide the computational characterization of both problems, separating the complexity in the size of the domain specification from that in the size of the formula. Specifically we establish them to be EXPTIME-complete and 2EXPTIME-complete, respectively, for both problems. In doing so, we also show 2EXPTIME-hardness for strong cyclic plans, which was open."
23,Complexity of Scheduling Charging in the Smart Grid,Main,"['Scheduling', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2018/658,"The problem of optimally scheduling the charging demand of electric vehicles within the constraints of the electricity infrastructure is called the charge scheduling problem. The models of the charging speed, horizon, and charging demand determine the computational complexity of the charge scheduling problem. We show that for about 20 variants the problem is either in P or weakly NP-hard and dynamic programs exist to compute optimal solutions. About 10 other variants of the problem are strongly NP-hard, presenting a potentially significant obstacle to their use in practical situations of scale. An experimental study establishes up to what parameter values the dynamic programs can determine optimal solutions in a couple of minutes."
24,"Traffic Light Scheduling, Value of Time, and Incentives",Main,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2018/659,"We study the intersection signalling control problem for cars with heterogeneous valuations of time (VoT). We are interested in a control algorithm that has some desirable properties: (1) it induces cars to report their VoT truthfully, (2) it minimizes the value of time lost for cars waiting at the intersection, and (3) it is computationally efficient. We obtain three main results: (1) We describe a computationally efficient heuristic forward search approach to solve the static problem. Simulation results show that this method is significantly faster than the dynamic-programming approach to solve the static problem (which is by itself polynomial time). We therefore believe that our algorithm can be commercially implemented. (2) We extend the solution of the static problem to the dynamic case. We couple our algorithm with a carefully designed payment scheme which yields an incentive compatible mechanism. In other words, it is the best interest of each car to truthfully report its VoT. (3) We describe simulation results that compare the social welfare obtained by our scheduling algorithm, as measured by the total value of waiting time, to the social welfare obtained by other intersection signalling control methods."
25,"Unchaining the Power of Partial Delete Relaxation, Part II: Finding Plans with Red-Black State Space Search",Main,"['Planning Algorithms', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/660,"Red-black relaxation in classical planning allows to interpolate between delete-relaxed and real planning. Yet the traditional use of relaxations to generate heuristics restricts relaxation usage to tractable fragments. How to actually tap into the red-black relaxation's interpolation power? Prior work has devised red-black state space search (RBS) for intractable red-black planning, and has explored two uses: proving unsolvability, generating seed plans for plan repair. Here, we explore the generation of plans directly through RBS. We design two enhancements to this end: (A) use a known tractable fragment where possible, use RBS for the intractable parts; (B) check RBS state transitions for realizability, spawn relaxation refinements where the check fails. We show the potential merits of both techniques on IPC benchmarks."
26,Model Checking Probabilistic Epistemic Logic for Probabilistic Multiagent Systems,Main,['Planning with Incomplete information'],https://www.ijcai.org/proceedings/2018/661,"In this work we study the model checking problem for probabilistic multiagent systems with respect to the probabilistic epistemic logic PETL, which can specify both temporal and epistemic properties. We show that under the realistic assumption of uniform schedulers, i.e., the choice of every agent depends only on its observation history, PETL model checking is undecidable. By restricting the class of schedulers to be memoryless schedulers, we show that the problem becomes decidable. More importantly, we design a novel algorithm which reduces the model checking problem into a mixed integer non-linear programming problem, which can then be solved by using an SMT solver. The algorithm has been implemented in an existing model checker and experiments are conducted on examples from the IPPC competitions."
27,Goal-HSVI: Heuristic Search Value Iteration for Goal POMDPs,Main,"['POMDPs', 'Theoretical Foundations of Planning', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2018/662,"Partially observable Markov decision processes (POMDPs) are the standard models for planning under uncertainty with both finite and infinite horizon. Besides the well-known discounted-sum objective, indefinite-horizon objective (aka Goal-POMDPs) is another classical objective for POMDPs. In this case, given a set of target states and a positive cost for each transition, the optimization objective is to minimize the expected total cost until a target state is reached. In the literature, RTDP-Bel or heuristic search value iteration (HSVI) have been used for solving Goal-POMDPs. Neither of these algorithms has theoretical convergence guarantees, and HSVI may even fail to terminate its trials. We give the following contributions: (1) We discuss the challenges introduced in Goal-POMDPs and illustrate how they prevent the original HSVI from converging. (2) We present a novel algorithm inspired by HSVI, termed Goal-HSVI, and show that our algorithm has convergence guarantees. (3) We show that Goal-HSVI outperforms RTDP-Bel on a set of well-known examples."
28,Learning to Infer Final Plans in Human Team Planning,Main,"['Applications of Planning', 'Activity and Plan Recognition']",https://www.ijcai.org/proceedings/2018/663,"We envision an intelligent agent that analyzes conversations during human team meetings in order to infer the team’s plan, with the purpose of providing decision support to strengthen that plan. We present a novel learning technique to infer teams' final plans directly from a processed form of their planning conversation. Our method employs reinforcement learning to train a model that maps features of the discussed plan and patterns of dialogue exchange among participants to a final, agreed-upon plan. We employ planning domain models to efficiently search the large space of possible plans, and the costs of candidate plans serve as the reinforcement signal. We demonstrate that our technique successfully infers plans within a variety of challenging domains, with higher accuracy than prior art. With our domain-independent feature set, we empirically demonstrate that our model trained on one planning domain can be applied to successfully infer team plans within a novel planning domain."
29,Small Undecidable Problems in Epistemic Planning,Main,['Theoretical Foundations of Planning'],https://www.ijcai.org/proceedings/2018/664,"Epistemic planning extends classical planning with knowledge and is based on dynamic epistemic logic (DEL). The epistemic planning problem is undecidable in general. We exhibit a small undecidable subclass of epistemic planning over 2-agent S5 models with a fixed repertoire of one action, 6 propositions and a fixed goal. We furthermore consider a variant of the epistemic planning problem where the initial knowledge state is an automatic structure, hence possibly infinite. In that case, we show the epistemic planning problem with 1 public action and 2 propositions to be undecidable, while it is known to be decidable  with public actions over finite models. Our results are obtained by reducing the reachability problem over small universal cellular automata. While our reductions yield a goal formula that displays the common knowledge operator, we show, for each of our considered epistemic problems, a reduction into an epistemic planning problem for a common-knowledge-operator-free goal formula by using 2 additional actions."
30,Effect-Abstraction Based Relaxation for Linear Numeric Planning,Main,"['Temporal and Hybrid planning', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/665,"This paper studies an effect-abstraction based relaxation   for reasoning about linear numeric planning problems. The effect-abstraction   decomposes non-constant linear numeric effects into actions with conditional   effects over additive constant numeric effects. With little effort, on this   compiled version, it is possible to use known subgoaling based relaxations   and relative heuristics. The combination of these two steps leads to a novel   relaxation based heuristic. Theoretically, the relaxation is proved tighter   than previous interval based relaxation and leading to safe-pruning   heuristics. Empirically, a heuristic developed on this relaxation leads to   substantial improvements for a class of  problems that are currently out of   the reach of state-of-the-art numeric planners."
31,Organizing Experience: a Deeper Look at Replay Mechanisms for Sample-Based Planning in Continuous State Domains,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2018/666,"Model-based strategies for control are critical to obtain sample efficient learning. Dyna is a planning paradigm that naturally interleaves learning and planning, by simulating one-step experience to update the action-value function. This elegant planning strategy has been mostly explored in the tabular setting. The aim of this paper is to revisit sample-based planning, in stochastic and continuous domains with learned models. We first highlight the flexibility afforded by a model over Experience Replay (ER). Replay-based methods can be seen as stochastic planning methods that repeatedly sample from a buffer of recent agent-environment interactions and perform updates to improve data efficiency. We show that a model, as opposed to a replay buffer, is particularly useful for specifying which states to sample from during planning, such as predecessor states that propagate information in reverse from a state more quickly. We introduce a semi-parametric model learning approach, called Reweighted Experience Models (REMs), that makes it simple to sample next states or predecessors. We demonstrate that REM-Dyna exhibits similar advantages over replay-based methods in learning in continuous state problems, and that the performance gap grows when moving to stochastic domains, of increasing size."
32,Scalable Initial State Interdiction for Factored MDPs,Main,"['Markov Decisions Processes', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2018/667,"We propose a novel Stackelberg game model of MDP interdiction in which the defender modifies the initial state of the planner, who then responds by computing an optimal policy starting with that state. We first develop a novel approach for MDP interdiction in factored state space that allows the defender to modify the initial state. The resulting approach can be computationally expensive for large factored MDPs. To address this, we develop several interdiction algorithms that leverage variations of reinforcement learning using both linear and non-linear function approximation. Finally, we extend the interdiction framework to consider a Bayesian interdiction problem in which the interdictor is uncertain about some of the planner's initial state features. Extensive experiments demonstrate the effectiveness of our approaches."
33,Counterplanning using Goal Recognition and Landmarks,Main,"['Activity and Plan Recognition', 'Distributed;Multi-agent Planning', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/668,"In non-cooperative multi-agent systems, agents might want to prevent the opponents from achieving their goals. One alternative to solve this task would be using counterplanning to generate a plan that allows an agent to block other's to reach their goals. In this paper, we introduce a fully automated domain-independent approach for counterplanning. It combines; goal recognition to infer an opponent's goal; landmarks' computation to identify subgoals that can be used to block opponents' goals achievement; and classical automated planning to generate plans that prevent the opponent's goals achievement. Experimental results in several domains show the benefits of our novel approach."
34,Planning in Factored State and Action Spaces with Learned Binarized Neural Network Transition Models,Main,"['Model-Based Reasoning', 'Other approaches to planning']",https://www.ijcai.org/proceedings/2018/669,"In this paper, we leverage the efficiency of Binarized Neural Networks (BNNs) to learn complex state transition models of planning domains with discretized factored state and action spaces. In order to directly exploit this transition structure for planning, we present two novel compilations of the learned factored planning problem with BNNs based on reductions to Boolean Satisfiability (FD-SAT-Plan) as well as Binary Linear Programming (FD-BLP-Plan). Experimentally, we show the effectiveness of learning complex transition models with BNNs, and test the runtime efficiency of both encodings on the learned factored planning problem. After this initial investigation, we present an incremental constraint generation algorithm based on generalized landmark constraints to improve the planning accuracy of our encodings. Finally, we show how to extend the best performing encoding (FD-BLP-Plan+) beyond goals to handle factored planning problems with rewards."
35,Dynamic Resource Routing using Real-Time Dynamic Programming,Main,"['Markov Decisions Processes', 'Planning under Uncertainty', 'Real-time Planning', 'Applications of Planning']",https://www.ijcai.org/proceedings/2018/670,"Acquiring available resources in stochastic environments becomes more and more important to future mobility. For instance, cities like Melbourne, Canberra and San Francisco install sensors that detect in real-time whether a parking spot (resource) is available or not. In such environments, the current state of the resources may be fully observable, although the future development is stochastic. In order to reduce the traffic, such cities want to fully exploit parking spots, such that the amount of searching cars is minimized. Thus, we formulate a problem setting where the expected seek time for each driver is minimized. This problem can be modeled by a Markov Decision Process (MDP) and solved using standard algorithms. In this paper, we focus on the setting, where pre-computation is not possible and search policies have to be computed on the fly. Our approach is based on state-of-the-art Real-Time Dynamic Programming (RTDP) approaches. However, standard RTDP approaches do not perform well on this specific problem setting as shown in our experiments. We introduce adapted bounds and approximations that exploit the specific nature of the problem in order to improve the performance significantly."
36,Hierarchical Expertise Level Modeling for User Specific Contrastive Explanations,Main,['Robot Planning'],https://www.ijcai.org/proceedings/2018/671,"There is a growing interest within the AI research community in developing autonomous systems capable of explaining their behavior to users. However, the problem of computing explanations for users of different levels of expertise has received little research attention. We propose an approach for addressing this problem by representing the user's understanding of the task as an abstraction of the domain model that the planner uses. We present algorithms for generating minimal explanations in cases where this abstract human model is not known. We reduce the problem of generating an explanation to a search over the space of abstract models and show that while the complete problem is NP-hard, a greedy algorithm can provide good approximations of the optimal solution. We also empirically show that our approach can efficiently compute explanations for a variety of problems."
37,"LP Heuristics over Conjunctions: Compilation, Convergence, Nogood Learning",Main,"['Planning Algorithms', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/672,"Two strands of research in classical planning are LP heuristics and conjunctions to improve approximations. Combinations of the two have also been explored. Here, we focus on convergence properties, forcing the LP heuristic to equal the perfect heuristic h* in the limit. We show that, under reasonable assumptions, partial variable merges are strictly dominated by the compilation Pi^C of explicit conjunctions, and that both render the state equation heuristic equal to h* for a suitable set C of conjunctions. We show that consistent potential heuristics can be computed from a variant of Pi^C, and that such heuristics can represent h* for suitable C. As an application of these convergence properties, we consider sound nogood learning in state space search, via refining the set C. We design a suitable refinement method to this end. Experiments on IPC benchmarks show significant performance improvements in several domains."
38,Completeness-Preserving Dominance Techniques for Satisficing Planning,Main,"['Planning Algorithms', 'Search in Planning and Scheduling', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/673,"Dominance pruning methods have recently been introduced for optimal planning. They compare states based on their goal distance to prune those that can be proven to be worse than others. In this paper, we introduce dominance techniques for satisficing planning. We extend the definition of dominance, showing that being closer to the goal is not a prerequisite for dominance in the satisficing setting. We develop a new method to automatically find dominance relations in which a state dominates another if it has achieved more serializable sub-goals. We take advantage of dominance relations in different ways; while in optimal planning their usage focused on dominance pruning and action selection, we also use it to guide enforced hill-climbing search, resulting in a complete algorithm."
39,Admissible Abstractions for Near-optimal Task and Motion Planning,Main,['Robot Planning'],https://www.ijcai.org/proceedings/2018/674,"We define an admissibility condition for abstractions expressed using angelic semantics and show that these conditions allow us to accelerate planning while preserving the ability to find the optimal motion plan.  We then derive admissible abstractions for two motion planning domains with continuous state.  We extract upper and lower bounds on the cost of concrete motion plans using local metric and topological properties of the problem domain.  These bounds guide the search for a plan while maintaining performance guarantees.  We show that abstraction can dramatically reduce the complexity of search relative to a direct motion planner.  Using our abstractions, we find near-optimal motion plans in planning problems involving 10^13 states without using a separate task planner."
40,PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement Learning for Robust Decision-Making,Main,['Applications of Planning'],https://www.ijcai.org/proceedings/2018/675,"Reinforcement learning and symbolic planning have both been used to build intelligent autonomous agents. Reinforcement learning relies on learning from interactions with real world, which often requires an unfeasibly large amount of experience. Symbolic planning relies on manually crafted symbolic knowledge, which may not be robust to domain uncertainties and changes. In this paper we present a unified framework PEORL that integrates symbolic planning with hierarchical reinforcement learning (HRL) to cope with decision-making in dynamic environment with uncertainties. Symbolic plans are used to guide the agent's task execution and learning, and the learned experience is fed back to symbolic knowledge to improve planning. This method leads to rapid policy search and robust symbolic plans in complex domains. The framework is tested on benchmark domains of HRL."
41,Minimax-Regret Querying on Side Effects for Safe Optimality in Factored Markov Decision Processes,Main,"['Markov Decisions Processes', 'Planning with Incomplete information']",https://www.ijcai.org/proceedings/2018/676,"As it achieves a goal on behalf of its human user, an autonomous agent's actions may have side effects that change features of its environment in ways that negatively surprise its user. An agent that can be trusted to operate safely should thus only change features the user has explicitly permitted.  We formalize this problem, and develop a planning algorithm that avoids potentially negative side effects given what the agent knows about (un)changeable features. Further, we formulate a provably minimax-regret querying strategy for the agent to selectively ask the user about features that it hasn't explicitly been told about. We empirically show how much faster it is than a more exhaustive approach and how much better its queries are than those found by the best known heuristic."
42,Bayesian Active Edge Evaluation on Expensive Graphs,Main,"['Real-time Planning', 'Robot Planning']",https://www.ijcai.org/proceedings/2018/679,"We consider the problem of real-time motion planning that requires evaluating a minimal number of edges on a graph to quickly discover collision-free paths. Evaluating edges is expensive, both for robots with complex geometries like robot arms, and for robots sensing the world online like UAVs. Until now, this challenge has been addressed via laziness, i.e. deferring edge evaluation until absolutely necessary, with the hope that edges turn out to be valid. However, all edges are not alike in value - some have a lot of potentially good paths flowing through them, and some others encode the likelihood of neighbouring edges being valid. This leads to our key insight - instead of passive laziness, we can actively choose edges that reduce the uncertainty about the validity of paths. We show that this is equivalent to the Bayesian active learning paradigm of decision region determination (DRD). However, the DRD problem is not only combinatorially hard but also requires explicit enumeration of all possible worlds. We propose a novel framework that combines two DRD algorithms, DIRECT and BISECT, to overcome both issues. We show that our approach outperforms several state-of-the-art algorithms on a spectrum of planning problems for mobile robots, manipulators and autonomous helicopters."
43,Policy Optimization with Second-Order Advantage Information,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2018/699,"Policy optimization on high-dimensional continuous control tasks exhibits its difficulty caused by the large variance of the policy gradient estimators. We present the action subspace dependent gradient (ASDG) estimator which incorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a unified framework to reduce the variance. To invoke RB, our proposed algorithm (POSA) learns the underlying factorization structure among the action space based on the second-order advantage information.  POSA captures the quadratic information explicitly and efficiently by utilizing the wide \& deep architecture. Empirical studies show that our proposed approach demonstrates the performance improvements on high-dimensional synthetic settings and OpenAI Gym's MuJoCo continuous control tasks."
44,Inductive Certificates of Unsolvability for Domain-Independent Planning,Best Sister Conferences,['Theoretical Foundations of Planning'],https://www.ijcai.org/proceedings/2018/730,"If a planning system outputs a solution for a given problem, it is simple to verify that the solution is valid. However, if a planner claims that a task is unsolvable, we currently have no choice but to trust the planner blindly. We propose a sound and complete class of certificates of unsolvability which can be verified efficiently by an independent program. To highlight their practical use, we show how these certificates can be generated for a wide range of state-of-the-art planning techniques with only polynomial overhead for the planner."
45,Cost-Based Goal Recognition for the Path-Planning Domain,Best Sister Conferences,"['Activity and Plan Recognition', 'Applications of Planning']",https://www.ijcai.org/proceedings/2018/747,"""Plan recognition as planning"" uses an off-the-shelf planner to perform goal recognition. In this paper, we apply the technique to path-planning. We show that a simpler formula provides an identical result in all but one set of conditions and, further, that identical ranking of goals by probability can be achieved without using any observations other than the agent's start location and where she is ""now""."
46,Operator Counting Heuristics for Probabilistic Planning,Best Sister Conferences,"['Markov Decisions Processes', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2018/758,"For the past 25 years, heuristic search has been used to solve domain-independent probabilistic planning problems, but with heuristics that determinise the problem and ignore precious probabilistic information. In this paper, we present a generalization of the operator-counting family of heuristics to Stochastic Shortest Path problems (SSPs) that is able to represent the probability of the actions outcomes. Our experiments show that the equivalent of the net change heuristic in this generalized framework obtains significant run time and coverage improvements over other state-of-the-art heuristics in different planners."
47,Greedy Stone Tower Creations with a Robotic Arm,Best Sister Conferences,['Planning Algorithms'],https://www.ijcai.org/proceedings/2018/760,"Predominately, robotic construction is applied as prefabrication in structured indoor environments with standard building materials. Our work, on the other hand, focuses on utilizing irregular materials found on-site, such as rubble and rocks, for autonomous construction. We present a pipeline to detect arbitrarily placed objects in a scene and form a structure out of the detected objects. The next best stacking pose is selected using a searching method employing gradient descent with random initial orientations, exploiting a physics engine. This approach is validated in an experimental setup using a robotic manipulator by constructing balancing vertical stacks without mortars and adhesives. We show the results of eleven consecutive trials to form such towers autonomously using four arbitrarily in front of the robot placed rocks."
48,Bridging the Gap Between Theory and Practice in Influence Maximization: Raising Awareness about HIV among Homeless Youth,Best Sister Conferences,"['Applications of Planning', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2018/761,"This paper reports on results obtained by deploying HEALER and DOSIM (two AI agents for social influence maximization) in the real-world, which assist service providers in maximizing HIV awareness in real-world homeless-youth social networks. These agents recommend key ""seed"" nodes in social networks, i.e., homeless youth who would maximize HIV awareness in their real-world social network. While prior research on these agents published promising simulation results from the lab, the usability of these AI agents in the real-world was unknown. This paper presents results from three real-world pilot studies involving 173 homeless youth across two different homeless shelters in Los Angeles. The results from these pilot studies illustrate that HEALER and DOSIM outperform the current modus operandi of service providers by ~160% in terms of information spread about HIV among homeless youth."
49,Solving Multi-Agent Path Finding on Strongly Biconnected Digraphs (Extended Abstract),Journal,"['Robot Planning', 'Planning Algorithms', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2018/785,"We present and evaluate diBOX, an algorithm for multi-agent path finding on strongly biconnected directed graphs. diBOX runs in polynomial time, computes suboptimal solutions and is complete for instances on strongly biconnected digraphs with at least two unoccupied positions. A detailed empirical analysis shows a good scalability for diBOX."
50,Fact-Alternating Mutex Groups for Classical Planning (Extended Abstract),Journal,"['Theoretical Foundations of Planning', 'Planning Algorithms']",https://www.ijcai.org/proceedings/2018/793,"Mutex groups are defined in the context of STRIPS planning as sets of facts out of which, maximally, one can be true in any state reachable from the initial state. This  work provides a complexity analysis showing that inference of mutex groups is as hard as planning itself (PSPACE-Complete) and it also shows a tight relationship between mutex groups and graph cliques. Furthermore, we propose a new type of mutex group called a fact-alternating mutex group (fam-group) of which inference is NP-Complete. We introduce an algorithm for the inference of fam-groups based on integer linear programming that is complete with respect to the maximal fam-groups and we demonstrate that fam-groups can be beneficial in the translation of planning tasks into finite domain representation, for the detection of dead-end state and for the pruning of spurious operators. The experimental evaluation of the pruning algorithm shows a substantial increase in a number of solved tasks in domains from the optimal deterministic track of the last two planning competitions (IPC 2011 and 2014)."
51,"Interactive Learning and Decision Making: Foundations, Insights & Challenges",Early Career,['Planning under Uncertainty'],https://www.ijcai.org/proceedings/2018/813,"Designing ""teams of intelligent agents that successfully coordinate and learn about their complex environments inhabited by other agents (such as humans)"" is one of the major goals of AI, and it is the challenge that I aim to address in my research. In this paper I give an overview of some of the foundations, insights and challenges in this field of Interactive Learning and Decision Making."
52,Advances and Challenges in Privacy Preserving Planning,Early Career,"['Planning Algorithms', 'Distributed;Multi-agent Planning']",https://www.ijcai.org/proceedings/2018/816,"Collaborative privacy-preserving planning (CPPP) is a multi-agent planning task in which agents need to achieve a common set of goals without revealing certain private information. CPPP has gained attention in recent years as an important sub area of multi agent planning, presenting new challenges to the planning community. In this paper we describe recent advancements, and outline open problems and future directions in this field.  We begin with describing different models of privacy, such as weak and strong privacy, agent privacy, and cardinality preserving privacy. We then discuss different solution approaches, focusing on the two prominent methods --- joint creation of a global coordination scheme first, followed by independent planning to extend the global scheme with private actions; and collaborative local planning where agents communicate information concerning their planning process. In both cases a heuristic is needed to guide the search process. We describe several adaptations of well known classical planning heuristic to CPPP, focusing on the difficulties in computing the heuristic without disclosing private information."
53,Learning Portable Symbolic Representations,Doctoral Consortium,['Hierarchical planning'],https://www.ijcai.org/proceedings/2018/826,"An open question in artificial intelligence is how to learn useful representations of the real world. One approach is to learn symbols, which represent the world and its contents, as well as models describing the effects on these symbols when interacting with the world. To date, however, research has investigated learning such representations for a single specific task. Our research focuses on approaches to learning these models in a domain-independent manner. We intend to use these symbolic models to build even higher levels of abstraction, creating a hierarchical representation which could be used to solve complex tasks. This would allow an agent to gather knowledge over the course of its lifetime, which could then be leveraged when faced with a new task, obviating the need to relearn a model every time a new unseen problem is encountered."
54,Intelligent Decision Support for Human Team Planning,Doctoral Consortium,"['Applications of Planning', 'Activity and Plan Recognition']",https://www.ijcai.org/proceedings/2018/828,"In my thesis, I develop computational models for an agent providing intelligent decision support (IDS) during human team planning sessions. My focus is on the development of an agent that help a team of human planners reach an agreement and produce high-quality plans prior to plan execution. I intend to develop novel techniques for an IDS agent that can 1) infer the team's intended plan from their planning conversation, 2) predict parts of the plan where the team's shared understanding is weak, and 3) suggest a resolution strategy when plan conflicts occur among teammates."
55,Optimal Multi-robot Task Planning: from Synthesis to Execution (and Back),Doctoral Consortium,['Robot Planning'],https://www.ijcai.org/proceedings/2018/829,"Integrated task planning and execution is a challenging problem with several applications in AI and robotics. In this work we consider the problem of generating and executing optimal plans for multi-robot systems under temporal and ordering constraints. More specifically, we propose an approach that unites the power of Optimization Modulo Theories with the flexibility of an on-line executive, providing optimal solutions for task planning, and runtime feedback on their execution."
56,Data-driven Onboard Scheduling for an Autonomous Observation Satellite,Doctoral Consortium,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2018/830,"Observation requests for autonomous observation satellites are dynamically generated. Considering the limited computing resources, a data-driven onboard scheduling method combining AI techniques and polynomial-time heuristics is proposed in this work. To construct observation schedules, a framework with offline learning and onboard scheduling is adopted. A neural network is trained offline in ground stations to  assign the scheduling priority to observation requests in the onboard scheduling, based on the optimized historical schedules obtained by genetic algorithms which are computationally demanding to run onboard. The computational simulations show that the performance of the scheduling heuristic is enhanced using the data-driven framework."
57,Instructing Novice Users on How to Use Tools in DIY Projects,Demos,['Applications of Planning'],https://www.ijcai.org/proceedings/2018/844,"Novice users require assistance when performing handicraft tasks. Adequate instruction ensures task completion and conveys knowledge and abilities required to perform the task. We present an assistant teaching novice users how to operate electronic tools, such as drills, saws, and sanders, in the context of Do-It-Yourself (DIY) home improvement projects. First, the actions that need to be performed for the project are determined by a planner. Second, a dialogue manager capable of natural language interaction presents these actions as instructions to the user. Third, questions on these actions and involved objects are answered by generating appropriate ontology-based explanations."
58,Generating Plans for Cooperative Connected UAVs,Demos,"['Applications of Planning', 'Distributed;Multi-agent Planning']",https://www.ijcai.org/proceedings/2018/846,"We present a tool for graph coverage with a fleet of UAVs. The UAVs must achieve the coverage of an area under the constraint of staying connected with the base, where the mission supervisor starts the plan. With an OpenStreetMap interface, the user is able to choose a specific location on which the mission needs to be generated and observes the resulting plan being executed."
59,SynKit: LTL Synthesis as a Service,Demos,['Applications of Planning'],https://www.ijcai.org/proceedings/2018/848,"Automatic synthesis of software from specification is one of the classic problems in computer science. In the last decade, significant advances have been made in the synthesis of programs from specifications expressed in Linear Temporal Logic (LTL). LTL synthesis technology is central to a myriad of applications from the automated generation of controllers for Internet of Things devices, to the synthesis of control software for robotic applications. Unfortunately, the number of existing tools for LTL synthesis is limited, and using them requires specialized expertise. In this paper we present SynKit, a tool that offers LTL synthesis as a service. SynKit integrates a RESTful API and a web service with an editor, a solver, and a strategy visualizer."
60,Visualizations for an Explainable Planning Agent,Demos,"['Activity and Plan Recognition', 'Applications of Planning', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2018/849,"In this demonstration, we report on the visualization capabilities of an Explainable AI Planning (XAIP) agent that can support human-in-the-loop decision-making. Imposing transparency and explainability requirements on such agents is crucial for establishing human trust and common ground with an end-to-end automated planning system. Visualizing the agent's internal decision making processes is a crucial step towards achieving this. This may include externalizing the ""brain"" of the agent: starting from its sensory inputs, to progressively higher order decisions made by it in order to drive its planning components. We demonstrate these functionalities in the context of a smart assistant in the Cognitive Environments Laboratory at IBM's T.J. Watson Research Center."
61,Multi-Sensor Mobile Platform for the Recognition of Activities of Daily Living and their Environments based on Artificial Neural Networks,Demos,['Activity and Plan Recognition'],https://www.ijcai.org/proceedings/2018/859,"The recognition of Activities of Daily Living (ADL) and their environments based on sensors available in off-the-shelf mobile devices is an emerging topic. These devices are capable to acquire and process the sensors' data for the correct recognition of the ADL and their environments, providing a fast and reliable feedback to the user. However, the methods implemented in a mobile application for this purpose should be adapted to the low resources of these devices. This paper focuses on the demonstration of a mobile application that implements a framework, that forks their implementation in several modules, including data acquisition, data processing, data fusion and classification methods based on the sensors? data acquired from the accelerometer, gyroscope, magnetometer, microphone and Global Positioning System (GPS) receiver. The framework presented is a function of the number of sensors available in the mobile devices and implements the classification with Deep Neural Networks (DNN) that reports an accuracy between 58.02% and 89.15%."
62,Data-Driven Inventory Management and Dynamic Pricing Competition on Online Marketplaces,Demos,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2018/861,"Online markets are characterized by competition and limited demand information. In E-commerce, firms compete against each other using data-driven dynamic pricing and ordering strategies. To successfully manage both inventory levels as well as offer prices is a highly challenging task as (i) demand is uncertain, (ii) competitors strategically interact, and (iii) optimized pricing and ordering decisions are mutually dependent. Currently, retailers lack the possibility to test and evaluate their algorithms appropriately before releasing them into the real world. To study joint dynamic ordering and pricing competition on online marketplaces, we built an interactive simulation platform. To be both flexible and scalable, the platform has a microservice-based architecture and allows handling dozens of competing merchants and streams of consumers with configurable characteristics. Further, we deployed and compared different pricing and ordering strategies, from simple rule-based ones to highly sophisticated data-driven strategies which are based on state-of-the-art demand learning techniques and efficient dynamic optimization models."
63,IBM Scenario Planning Advisor: Plan Recognition as AI Planning in Practice,Demos,"['Activity and Plan Recognition', 'Applications of Planning']",https://www.ijcai.org/proceedings/2018/864,"We present the IBM Research Scenario Planning Advisor (SPA), a decision support system that allows users to generate diverse alternate scenarios of the future and enhance their ability to imagine the different possible outcomes, including unlikely but potentially impactful futures. The system includes tooling for experts to intuitively encode their domain knowledge, and uses AI Planning to reason about this knowledge and the current state of the world, including news and social media, when generating scenarios."
64,Curly: An AI-based Curling Robot Successfully Competing in the Olympic Discipline of Curling,Demos,"['Planning under Uncertainty', 'Planning with Incomplete information']",https://www.ijcai.org/proceedings/2018/870,"Most artificial intelligence (AI) based learning systems act in virtual or laboratory environments. Here we demonstrate an AI-based curling robot system named `Curly' that competes on a real-world curling ice sheet. Curly encompasses (1) an AI-based curling strategy and simulation engine under consideration of the high `icy' uncertainty, (2) the thrower robot enabled by autonomous driving with traction control, and (3) the skip robot that allows to recognize the curling field and stone configuration based on vision technology. The Curly performed well both: in classical game situations and when interacting with human opponents, namely, the top-ranked Korean amateur high school curling team."
