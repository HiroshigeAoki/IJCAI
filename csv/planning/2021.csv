,title,track,categories,url,desc
0,Online Selection of Diverse Committees,Main,"['Markov Decisions Processes', 'Applications of Planning']",https://www.ijcai.org/proceedings/2021/22,"Citizens' assemblies need to represent subpopulations according to their proportions in the general population. These large committees are often constructed in an online fashion by contacting people, asking for the demographic features of the volunteers, and deciding to include them or not. This raises a trade-off between the number of people contacted (and the incurring cost) and the representativeness of the committee. We study three methods, theoretically and experimentally: a greedy algorithm that includes volunteers as long as proportionality is not violated; a non-adaptive method that includes a volunteer with a probability depending only on their features, assuming that the joint feature distribution in the volunteer pool is known; and a reinforcement learning based approach when this distribution is not known a priori but learnt online."
1,State-Aware Value Function Approximation with Attention Mechanism for Restless Multi-armed Bandits,Main,"['Planning and Scheduling', 'Markov Decisions Processes']",https://www.ijcai.org/proceedings/2021/64,"The restless multi-armed bandit (RMAB) problem is a generalization of the multi-armed bandit with non-stationary rewards. Its optimal solution is intractable due to exponentially large state and action spaces with respect to the number of arms. Existing approximation approaches, e.g., Whittle's index policy, have difficulty in capturing either temporal or spatial factors such as impacts from other arms. We propose considering both factors using the attention mechanism, which has achieved great success in deep learning. Our state-aware value function approximation solution comprises an attention-based value function approximator and a Bellman equation solver. The attention-based coordination module capture both spatial and temporal factors for arm coordination. The Bellman equation solver utilizes the decoupling structure of RMABs to acquire solutions with significantly reduced computation overheads. In particular, the time complexity of our approximation is linear in the number of arms. Finally, we illustrate the effectiveness and investigate the properties of our proposed method with numerical experiments."
2,Bounded-cost Search Using Estimates of Uncertainty,Main,['Search in Planning and Scheduling'],https://www.ijcai.org/proceedings/2021/231,"Many planning problems are too hard to solve optimally.  In bounded-cost search, one attempts to find, as quickly as possible, a plan that costs no more than a user-provided absolute cost bound.  Several algorithms have been previously proposed for this setting, including Potential Search (PTS) and Bounded-cost Explicit Estimation Search (BEES).  BEES attempts to improve on PTS by predicting whether nodes will lead to plans within the cost bound or not.  This paper introduces a relatively simple algorithm, Expected Effort Search (XES), which uses not just point estimates but belief distributions in order to estimate the probability that a node will lead to a plan within the bound.  XES's expansion order minimizes expected search time in a simplified formal model.  Experimental results on standard planning and search benchmarks show that it consistently exhibits strong performance, outperforming both PTS and BEES.  We also derive improved variants of BEES that can exploit belief distributions.  These new methods advance the recent trend of taking advantage of uncertainty estimates in deterministic single-agent search."
3,Best-Effort Synthesis: Doing Your Best Is Not Harder Than Giving Up,Main,['Theoretical Foundations of Planning'],https://www.ijcai.org/proceedings/2021/243,"We study best-effort synthesis under environment assumptions specified in LTL, and show that this problem has exactly the same computational complexity of standard LTL synthesis: 2EXPTIME-complete. We provide optimal algorithms for computing best-effort strategies, both in the case of LTL over infinite traces and LTL over finite traces (i.e., LTLf). The latter are particularly well suited for implementation."
4,Finite-Trace and Generalized-Reactivity Specifications in Temporal Synthesis,Main,['Theoretical Foundations of Planning'],https://www.ijcai.org/proceedings/2021/255,"Linear Temporal Logic (LTL) synthesis aims at automatically synthesizing a program that complies with desired properties expressed in LTL. Unfortunately it has been proved to be too difficult computationally to perform full LTL synthesis. There have been two success stories with LTL synthesis, both having to do with the form of the specification. The first is the GR(1) approach: use safety conditions to determine the possible transitions in a game between the environment and the agent, plus one powerful notion of fairness, Generalized Reactivity(1), or GR(1). The second, inspired by AI planning, is focusing on finite-trace temporal synthesis, with LTLf (LTL on finite traces) as the specification language. In this paper we take these two lines of work and bring them together. We first study the case in which we have an LTLf agent goal and a GR(1) assumption. We then add to the framework safety conditions for both the environment and the agent, obtaining a highly expressive yet still scalable form of LTL synthesis."
5,Efficient PAC Reinforcement Learning in Regular Decision Processes,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2021/279,"Recently regular decision processes have been proposed as a well-behaved form of non-Markov decision process. Regular decision processes are characterised by a transition function and a reward function that depend on the whole history, though regularly (as in regular languages). In practice both the transition and the reward functions can be seen as finite transducers. We study reinforcement learning in regular decision processes. Our main contribution is to show that a near-optimal policy can be PAC-learned in polynomial time in a set of parameters that describe the underlying decision process. We argue that the identified set of parameters is minimal and it reasonably captures the difficulty of a regular decision process."
6,Transforming Robotic Plans with Timed Automata to Solve Temporal Platform Constraints,Main,['Temporal and Hybrid Planning'],https://www.ijcai.org/proceedings/2021/287,"Task planning for mobile robots typically uses an abstract planning domain that ignores the low-level details of the specific robot platform. Therefore, executing a plan on an actual robot often requires additional steps to deal with the specifics of the robot platform. Such a platform can be modeled with timed automata and a set of temporal constraints that need to be satisfied during execution. In this paper, we describe how to transform an abstract plan into a platform-specific action sequence that satisfies all platform constraints. The transformation procedure first transforms the plan into a timed automaton, which is then combined with the platform automata while removing all transitions that violate any constraint. We then apply reachability analysis on the resulting automaton.  From any solution trace one can obtain the abstract plan extended by additional platform actions such that all platform constraints are satisfied.  We describe the transformation procedure in detail and provide an evaluation in two real-world robotics scenarios."
7,Reconciling Rewards with Predictive State Representations,Main,['POMDPs'],https://www.ijcai.org/proceedings/2021/299,"Predictive state representations (PSRs) are models of controlled non-Markov   observation sequences which exhibit the same generative process governing   POMDP observations without relying on an underlying latent state.  In that   respect, a PSR is indistinguishable from the corresponding POMDP.  However,   PSRs notoriously ignore the notion of rewards, which undermines the general   utility of PSR models for control, planning, or reinforcement learning.   Therefore, we describe a sufficient and necessary accuracy condition   which determines whether a PSR is able to accurately model POMDP rewards, we   show that rewards can be approximated even when the accuracy condition is not   satisfied, and we find that a non-trivial number of POMDPs taken from a   well-known third-party repository do not satisfy the accuracy condition.     We propose reward-predictive state representations (R-PSRs), a   generalization of PSRs which accurately models both observations and rewards,   and develop value iteration for R-PSRs.  We show that there is a mismatch   between optimal POMDP policies and the optimal PSR policies derived from   approximate rewards.  On the other hand, optimal R-PSR policies perfectly   match optimal POMDP policies, reconfirming R-PSRs as accurate state-less   generative models of observations and rewards."
8,Model-Based Reinforcement Learning for Infinite-Horizon Discounted Constrained Markov Decision Processes,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2021/347,"In many real-world reinforcement learning (RL) problems, in addition to maximizing the  objective, the learning agent has to  maintain some necessary safety constraints.  We formulate the problem of learning a safe policy as  an  infinite-horizon discounted Constrained Markov Decision Process (CMDP)  with an unknown transition probability matrix, where the safety requirements are modeled as   constraints on expected cumulative costs.  We propose two model-based constrained reinforcement learning (CRL) algorithms for learning a safe policy, namely, (i) GM-CRL algorithm,  where the algorithm has access to a generative model, and (ii) UC-CRL  algorithm,  where the algorithm learns the model using an upper confidence style online exploration method.   We characterize the sample complexity of these algorithms, i.e., the the number of samples needed to ensure a desired level of accuracy with high probability, both with respect to objective maximization and constraint satisfaction."
9,State-Based Recurrent SPMNs for Decision-Theoretic Planning under Partial Observability,Main,"['Model-Based Reasoning', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2021/348,"The sum-product network (SPN) has been extended to model sequence data with the recurrent SPN (RSPN), and to decision-making problems with sum-product-max networks (SPMN). In this paper, we build on the concepts introduced by these extensions and present state-based recurrent SPMNs (S-RSPMNs) as a generalization of SPMNs to sequential decision-making problems where the state may not be perfectly observed. As with recurrent SPNs, S-RSPMNs utilize a repeatable template network to model sequences of arbitrary lengths. We present an algorithm for learning compact template structures by identifying unique belief states and the transitions between them through a state matching process that utilizes augmented data.  In our knowledge, this is the first data-driven approach that learns graphical models for planning under partial observability, which can be solved efficiently. S-RSPMNs retain the linear solution complexity of SPMNs, and we demonstrate significant improvements in compactness of representation and the run time of structure learning and inference in sequential domains."
10,Reinforcement Learning for Route Optimization with Robustness Guarantees,Main,['Planning under Uncertainty'],https://www.ijcai.org/proceedings/2021/357,"Application of deep learning to NP-hard combinatorial optimization problems is an emerging research trend, and a number of interesting approaches have been published over the last few years. In this work we address robust optimization, which is a more complex variant where a max-min problem is to be solved. We obtain robust solutions by solving the inner minimization problem exactly and apply Reinforcement Learning to learn a heuristic for the outer problem. The minimization term in the inner objective represents an obstacle to existing RL-based approaches, as its value depends on the full solution in a non-linear manner and cannot be evaluated for partial solutions constructed by the agent over the course of each episode. We overcome this obstacle by defining the reward in terms of the one-step advantage over a baseline policy whose role can be played by any fast heuristic for the given problem. The agent is trained to maximize the total advantage, which, as we show, is equivalent to the original objective. We validate our approach by solving min-max versions of standard benchmarks for the Capacitated Vehicle Routing and the Traveling Salesperson Problem, where our agents obtain near-optimal solutions and improve upon the baselines."
11,Efficient Black-Box Planning Using Macro-Actions with Focused Effects,Main,"['Planning and Scheduling', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2021/554,"The difficulty of deterministic planning increases exponentially with search-tree depth. Black-box planning presents an even greater challenge, since planners must operate without an explicit model of the domain. Heuristics can make search more efficient, but goal-aware heuristics for black-box planning usually rely on goal counting, which is often quite uninformative. In this work, we show how to overcome this limitation by discovering macro-actions that make the goal-count heuristic more accurate. Our approach searches for macro-actions with focused effects (i.e. macros that modify only a small number of state variables), which align well with the assumptions made by the goal-count heuristic. Focused macros dramatically improve black-box planning efficiency across a wide range of planning domains, sometimes beating even state-of-the-art planners with access to a full domain model."
12,ME-MCTS: Online Generalization by Combining Multiple Value Estimators,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2021/555,"This paper addresses the challenge of online generalization in tree search. We propose Multiple Estimator Monte Carlo Tree Search (ME-MCTS), with a two-fold contribution: first, we introduce a formalization of online generalization that can represent existing techniques such as ""history heuristics"", ""RAVE"", or ""OMA"" -- contextual action value estimators or abstractors that generalize across specific contexts. Second, we incorporate recent advances in estimator averaging that enable guiding search by combining the online action value estimates of any number of such abstractors or similar types of action value estimators. Unlike previous work, which usually proposed a single abstractor for either the selection or the rollout phase of MCTS simulations, our approach focuses on the combination of multiple estimators and applies them to all move choices in MCTS simulations. As the MCTS tree itself is just another value estimator -- unbiased, but without abstraction -- this blurs the traditional distinction between action choices inside and outside of the MCTS tree. Experiments with three abstractors in four board games show significant improvements of ME-MCTS over MCTS using only a single abstractor, both for MCTS with random rollouts as well as for MCTS with static evaluation functions. While we used deterministic, fully observable games, ME-MCTS naturally extends to more challenging settings."
13,Learn to Intervene: An Adaptive Learning Policy for Restless Bandits in Application to Preventive Healthcare,Main,"['Applications of Planning', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2021/556,"In many public health settings, it is important for patients to adhere to health programs, such as taking medications and periodic health checks. Unfortunately, beneficiaries may gradually disengage from such programs, which is detrimental to their health. A concrete example of gradual disengagement has been observed by an organization that carries out a free automated call-based program for spreading preventive care information among pregnant women. Many women stop picking up calls after being enrolled for a few months. To avoid such disengagements, it is important to provide timely interventions. Such interventions are often expensive and can be provided to only a small fraction of the beneficiaries. We model this scenario as a restless multi-armed bandit (RMAB) problem, where each beneficiary is assumed to transition from one state to another depending on the intervention.  Moreover, since the transition probabilities are unknown a priori, we propose a Whittle index based Q-Learning mechanism and show that it converges to the optimal solution. Our method improves over existing learning-based methods for RMABs on multiple benchmarks from literature and also on the maternal healthcare dataset."
14,Type-WA*: Using Exploration in Bounded Suboptimal Planning,Main,"['Planning Algorithms', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2021/557,"Previous work on satisficing planning using greedy best-first search (GBFS) has shown that non-greedy, randomized exploration can help escape uninformative heuristic regions and solve hard problems faster. Despite their success when used with GBFS, such exploration techniques cannot be directly applied to bounded suboptimal algorithms like Weighted A* (WA*) without losing the solution-quality guarantees. In this work, we present Type-WA*, a novel bounded suboptimal planning algorithm that augments WA* with type-based exploration while still satisfying WA*'s theoretical solution-quality guarantee. Our empirical analysis shows that Type-WA* significantly increases the number of solved problems, when used in conjunction with each of three popular heuristics. Our analysis also provides insight into the runtime vs. solution cost trade-off."
15,Custom-Design of FDR Encodings: The Case of Red-Black Planning,Main,"['Planning Algorithms', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2021/558,"Classical planning tasks are commonly described in PDDL, while most planning systems operate on a grounded finite-domain representation (FDR). The translation of PDDL into FDR is complex and has a lot of choice points---it involves identifying so called mutex groups---but most systems rely on the translator that comes with Fast Downward. Yet the translation choice points can strongly impact performance. Prior work has considered optimizing FDR encodings in terms of the number of variables produced. Here we go one step further by proposing to custom-design FDR encodings, optimizing the encoding to suit particular planning techniques. We develop such a custom design here for red-black planning, a partial delete relaxation technique. The FDR encoding affects the causal graph and the domain transition graph structures, which govern the tractable fragment of red-black planning and hence affects the respective heuristic function. We develop integer linear programming techniques optimizing the scope of that fragment in the resulting FDR encoding. We empirically show that the performance of red-black planning can be improved through such FDR custom design."
16,Active Goal Recognition Design,Main,['Activity and Plan Recognition'],https://www.ijcai.org/proceedings/2021/559,"In Goal Recognition Design (GRD), the objective is to modify a domain to facilitate early detection of the goal of a subject agent.  Most previous work studies this problem in the offline setting, in which the observing agent performs its interventions before the subject begins acting.  In this paper, we generalize GRD to the online setting in which time passes and the observer's actions are interleaved with those of the subject. We illustrate weaknesses of existing metrics for GRD and propose an alternative better suited to online settings. We provide a formal definition of this Active GRD (AGRD) problem and study an algorithm for solving it.  AGRD occupies an interesting middle ground between passive goal recognition and strategic two-player game settings."
17,Stochastic Probing with Increasing Precision,Main,['Planning under Uncertainty'],https://www.ijcai.org/proceedings/2021/560,"We consider a selection problem with stochastic probing. There is a set of items whose values are drawn from independent distributions. The distributions are known in advance. Each item can be \emph{tested} repeatedly. Each test reduces the uncertainty about the realization of its value. We study a testing model, where the first test reveals if the realized value is smaller or larger than the median of the underlying distribution. Subsequent tests allow to further  narrow down the interval in which the realization is located. There is a limited number of possible tests, and our goal is to design near-optimal testing strategies that allow to maximize the expected value of the chosen item. We study both identical and non-identical distributions and develop polynomial-time algorithms with constant approximation factors in both scenarios."
18,Incorporating Queueing Dynamics into Schedule-Driven Traffic Control,Main,"['Applications of Planning', 'Planning and Scheduling', 'Real-time Planning']",https://www.ijcai.org/proceedings/2021/561,"Key to the effectiveness of schedule-driven approaches to real-time traffic control is an ability to accurately predict when sensed vehicles will arrive at and pass through the intersection. Prior work in schedule-driven traffic control has assumed a static vehicle arrival model. However, this static predictive model ignores the fact that the queue count and the incurred delay should vary as different partial signal timing schedules (i.e., different possible futures) are explored during the online planning process. In this paper, we propose an alternative arrival time model that incorporates queueing dynamics into this forward search process for a signal timing schedule, to more accurately capture how the intersection’s queues vary over time. As each search state is generated, an incremental queueing delay is dynamically projected for each vehicle. The resulting total queueing delay is then considered in addition to the cumulative delay caused by signal operations. We demonstrate the potential of this approach through microscopic traffic simulation of a real-world road network, showing a 10-15% reduction in average wait times over the schedule-driven traffic signal control system in heavy traffic scenarios."
19,Symbolic Dynamic Programming for Continuous State MDPs with Linear Program Transitions,Main,"['Markov Decisions Processes', 'Planning under Uncertainty']",https://www.ijcai.org/proceedings/2021/562,"Recent advances in symbolic dynamic programming (SDP) have significantly broadened the class of MDPs for which exact closed-form value functions can be derived. However, no existing solution methods can solve complex discrete and continuous state MDPs where a linear program determines state transitions --- transitions that are often required in problems with underlying constrained flow dynamics arising in problems ranging from traffic signal control to telecommunications bandwidth planning. In this paper, we present a novel SDP solution method for MDPs with LP transitions and continuous piecewise linear dynamics by introducing a novel, fully symbolic argmax operator. On three diverse domains, we show the first automated exact closed-form SDP solution to these challenging problems and the significant advantages of our SDP approach over discretized approximations."
20,Interference-free Walks in Time: Temporally Disjoint Paths,Main,"['Planning and Scheduling', 'Scheduling']",https://www.ijcai.org/proceedings/2021/563,"We investigate the computational complexity of finding temporally disjoint paths or walks in temporal graphs. There, the edge set changes over discrete time steps and a temporal path (resp. walk) uses edges that appear at monotonically increasing time steps. Two paths (or walks) are temporally disjoint if they never use the same vertex at the same time; otherwise, they interfere. This reflects applications in robotics, traffic routing, or finding safe pathways in dynamically changing networks. On the one extreme, we show that on general graphs the problem is computationally hard. The ""walk version"" is W[1]-hard when parameterized by the number of routes. However, it is polynomial-time solvable for any constant number of walks. The ""path version"" remains NP-hard even if we want to find only two temporally disjoint paths. On the other extreme, restricting the input temporal graph to have a path as underlying graph, quite counterintuitively, we find NP-hardness in general but also identify natural tractable cases."
21,Counterfactual Explanations for Optimization-Based Decisions in the Context of the GDPR,Main,['Scheduling'],https://www.ijcai.org/proceedings/2021/564,"The General Data Protection Regulations (GDPR) entitle individuals to explanations for automated decisions. The form, comprehensibility, and even existence of such explanations remain open problems, investigated as part of explainable AI. We adopt the approach of counterfactual explanations and apply it to decisions made by declarative optimization models. We argue that inverse combinatorial optimization is particularly suited for counterfactual explanations but that the computational difficulties and relatively nascent literature make its application a challenge. To make progress, we address the case of counterfactual explanations that isolate the minimal differences for an individual. We show that under two common optimization functions, full inverse optimization is unnecessary. In particular, we show that for functions of the form of the sum of weighted binary variables, which includes frameworks such as weighted MaxSAT, a solution can be found by solving a slightly modified version of the original optimization model. In contrast, the sum of weighted integer variables can be solved with a binary search over a series of modifications to the original model."
22,LTL-Constrained Steady-State Policy Synthesis,Main,['Markov Decisions Processes'],https://www.ijcai.org/proceedings/2021/565,"Decision-making policies for agents are often synthesized with the constraint that a  formal specification of behaviour is satisfied. Here we focus on infinite-horizon properties. On the one hand,  Linear Temporal Logic (LTL) is a popular example of a formalism for qualitative specifications. On the other hand, Steady-State Policy Synthesis (SSPS) has recently received considerable attention as it provides a more quantitative and more behavioural perspective on specifications, in terms of the frequency with which states are visited. Finally, rewards provide a classic framework for quantitative properties. In this paper, we study Markov decision processes (MDP) with the specification combining all these three types. The derived policy maximizes the reward among all policies ensuring the LTL specification with the given probability and adhering to the steady-state constraints. To this end, we provide a unified solution reducing the multi-type specification to a multi-dimensional long-run average reward. This is enabled by Limit-Deterministic Büchi Automata (LDBA), recently studied in the context of LTL model checking on MDP, and allows for an elegant solution through a simple linear programme. The algorithm also extends to the general omega-regular properties and runs in time polynomial in the sizes of the MDP as well as the LDBA."
23,Online Learning of Action Models for PDDL Planning,Main,"['Model-Based Reasoning', 'Planning Algorithms', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2021/566,"The automated learning of action models is widely recognised as a key and compelling challenge to address the difficulties of the manual specification of planning domains. Most state-of-the-art methods perform this learning offline from an input set of plan traces generated by the execution of (successful) plans.  However, how to generate informative plan traces for learning action models is still an open issue. Moreover, plan traces might not be available for a new environment. In this paper, we propose an algorithm for learning action models online, incrementally during the execution of plans. Such plans are generated to achieve goals that the algorithm decides online in order to obtain informative plan traces and reach states from which useful information can be learned. We show some fundamental theoretical properties of the algorithm, and we experimentally evaluate the online learning of the action models over a large set of IPC domains."
24,Polynomial-Time in PDDL Input Size: Making the Delete Relaxation Feasible for Lifted Planning,Main,"['Planning Algorithms', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2021/567,"Polynomial-time heuristic functions for planning are commonplace since 20 years. But polynomial-time in which input? Almost all existing approaches are based on a grounded task representation, not on the actual PDDL input which is exponentially smaller. This limits practical applicability to cases where the grounded representation is ""small enough"". Previous attempts to tackle this problem for the delete relaxation leveraged symmetries to reduce the blow-up. Here we take a more radical approach, applying an additional relaxation to obtain a heuristic function that runs in time polynomial in the size of the PDDL input. Our relaxation splits the predicates into smaller predicates of fixed arity K. We show that computing a relaxed plan is still NP-hard (in PDDL input size) for K>=2, but is polynomial-time for K=1. We implement a heuristic function for K=1 and show that it can improve the state of the art on benchmarks whose grounded representation is large."
25,Anytime Multi-Agent Path Finding via Large Neighborhood Search,Main,['Search in Planning and Scheduling'],https://www.ijcai.org/proceedings/2021/568,"Multi-Agent Path Finding (MAPF) is the challenging problem of computing collision-free paths for multiple agents. Algorithms for solving MAPF can be categorized on a spectrum. At one end are (bounded-sub)optimal algorithms that can find high-quality solutions for small problems. At the other end are unbounded-suboptimal algorithms that can solve large problems but usually find low-quality solutions. In this paper, we consider a third approach that combines the best of both worlds: anytime algorithms that quickly find an initial solution using efficient MAPF algorithms from the literature, even for large problems, and that subsequently improve the solution quality to near-optimal as time progresses by replanning subgroups of agents using Large Neighborhood Search. We compare our algorithm MAPF-LNS against a range of existing work and report significant gains in scalability, runtime to the initial solution, and speed of improving the solution."
26,Dynamic Rebalancing Dockless Bike-Sharing System based on Station Community Discovery,Main,"['Applications of Planning', 'Planning and Scheduling']",https://www.ijcai.org/proceedings/2021/569,"Influenced by the era of the sharing economy and mobile payment, Dockless Bike-Sharing System (Dockless BSS) is expanding in many major cities. The mobility of users constantly leads to supply and demand imbalance, which seriously affects the total profit and customer satisfaction. In this paper, we propose the Spatio-Temporal Mixed Integer Program (STMIP) with Flow-graphed Community Discovery (FCD) approach to rebalancing the system. Different from existing studies that ignore the route of trucks and adopt a centralized rebalancing, our approach considers the spatio-temporal information of trucks and discovers station communities for truck-based rebalancing. First, we propose the FCD algorithm to detect station communities. Significantly, rebalancing communities decomposes the centralized system into a distributed multi-communities system. Then, by considering the routing and velocity of trucks, we design the STMIP model with the objective of maximizing total profit, to find a repositioning policy for each station community. We design a simulator built on real-world data from DiDi Chuxing to test the algorithm performance. The extensive experimental results demonstrate that our approach outperforms in terms of service level, profit, and complexity compared with the state-of-the-art approach."
27,Synthesizing Good-Enough Strategies for LTLf Specifications,Main,"['Applications of Planning', 'Planning and Scheduling', 'Temporal and Hybrid Planning']",https://www.ijcai.org/proceedings/2021/570,"We consider the problem of synthesizing good-enough (GE)-strategies for linear temporal logic (LTL) over finite traces or LTLf for short. The problem of synthesizing GE-strategies for an LTL formula φ over infinite traces reduces to the problem of synthesizing winning strategies for the formula (∃Oφ)⇒φ where O is the set of propositions controlled by the system. We first prove that this reduction does not work for LTLf formulas. Then we show how to synthesize GE-strategies for LTLf formulas via the Good-Enough (GE)-synthesis of LTL formulas. Unfortunately, this requires to construct deterministic parity automata on infinite words, which is computationally expensive. We then show how to synthesize GE-strategies for LTLf formulas by a reduction to solving games played on deterministic Büchi automata, based on an easier construction of deterministic automata on finite words. We show empirically that our specialized synthesis algorithm for GE-strategies outperforms the algorithms going through GE-synthesis of LTL formulas by orders of magnitude."
28,Change the World - How Hard Can that Be? On the Computational Complexity of Fixing Planning Models,Main,"['Hierarchical Planning', 'Model-Based Reasoning', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2021/571,"Incorporating humans into AI planning is an important feature of flexible planning technology. Such human integration allows to incorporate previously unknown constraints, and is also an integral part of automated modeling assistance. As a foundation for integrating user requests, we study the computational complexity of determining the existence of changes to an existing model, such that the resulting model allows for specific user-provided solutions. We are provided with a planning problem modeled either in the classical (non-hierarchical) or hierarchical task network (HTN) planning formalism, as well as with a supposed-to-be solution plan, which is actually not a solution for the current model. Considering changing decomposition methods as well as preconditions and effects of actions, we show that most change requests are NP-complete though some turn out to be tractable."
29,Learning Temporal Plan Preferences from Examples: An Empirical Study,Main,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2021/572,"Temporal plan preferences are natural and important in a variety of applications. Yet users often find it difficult to formalize their preferences. Here we explore the possibility to learn preferences from example plans. Focusing on one preference at a time, the user is asked to annotate examples as good/bad. We leverage prior work on LTL formula learning to extract a preference from these examples. We conduct an empirical study of this approach in an oversubscription planning context, using hidden target formulas to emulate the user preferences. We explore four different methods for generating example plans, and evaluate performance as a function of domain and formula size. Overall, we find that reasonable-size target formulas can often be learned effectively."
30,On Weak Stubborn Sets in Classical Planning,Main,"['Planning Algorithms', 'Search in Planning and Scheduling', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2021/573,"Stubborn sets are a pruning technique for state-space search which is well established in optimal classical planning. In this paper, we show that weak stubborn sets introduced in recent work in planning are actually not weak stubborn sets in Valmari's original sense. Based on this finding, we introduce weak stubborn sets in the original sense for planning by providing a generalized definition analogously to generalized strong stubborn sets in previous work. We discuss the relationship of strong, weak and the previously called weak stubborn sets, thus providing a further step in getting an overall picture of the stubborn set approach in planning."
31,Learning Generalized Unsolvability Heuristics for Classical Planning,Main,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2021/574,"Recent work in classical planning has introduced dedicated techniques for detecting unsolvable states, i.e., states from which no goal state can be reached. We approach the problem from a generalized planning perspective and learn first-order-like formulas that characterize unsolvability for entire planning domains. We show how to cast the problem as a self-supervised classification task. Our training data is automatically generated and labeled by exhaustive exploration of small instances of each domain, and candidate features are automatically computed from the predicates used to define the domain. We investigate three learning algorithms with different properties and compare them to heuristics from the literature. Our empirical results show that our approach often captures important classes of unsolvable states with high classification accuracy. Additionally, the logical form of our heuristics makes them easy to interpret and reason about, and can be used to show that the characterizations learned in some domains capture exactly all unsolvable states of the domain."
32,Solving Partially Observable Stochastic Shortest-Path Games,Main,['Planning with Incomplete Information'],https://www.ijcai.org/proceedings/2021/575,"We study the two-player zero-sum extension of the partially observable stochastic shortest-path problem where one agent has only partial information about the environment. We formulate this problem as a partially observable stochastic game (POSG): given a set of target states and negative rewards for each transition, the player with imperfect information maximizes the expected undiscounted total reward until a target state is reached. The second player with the perfect information aims for the opposite.  We base our formalism on POSGs with one-sided observability (OS-POSGs) and give the following contributions: (1) we introduce a novel heuristic search value iteration algorithm that iteratively solves depth-limited variants of the game, (2) we derive the bound on the depth guaranteeing an arbitrary precision, (3) we propose a novel upper-bound estimation that allows early terminations, and (4) we experimentally evaluate the algorithm on a pursuit-evasion game."
33,The Fewer the Merrier: Pruning Preferred Operators with Novelty,Main,"['Planning and Scheduling', 'Search in Planning and Scheduling']",https://www.ijcai.org/proceedings/2021/576,"Heuristic search is among the best performing approaches to classical satisficing planning, with its performance heavily relying on informative and fast heuristics, as well as search-boosting and pruning techniques. While both heuristics and pruning techniques have gained much attention recently, search-boosting techniques in general, and preferred operators in particular have received less attention in the last decade.   Our work aims at bringing the light back to preferred operators research, with the introduction of preferred operators pruning technique, based on the concept of novelty. Continuing the research on novelty with respect to an underlying heuristic, we present the definition of preferred operators for such novelty heuristics. For that, we extend the previously defined concepts to operators, allowing us to reason about the novelty of the preferred operators. Our experimental evaluation shows the practical benefit of our suggested approach, compared to the currently used methods."
34,TANGO: Commonsense Generalization in Predicting Tool Interactions for Mobile Manipulators,Main,['Robot Planning'],https://www.ijcai.org/proceedings/2021/577,"Robots assisting us in factories or homes must learn to make use of objects as tools to perform tasks, e.g., a tray for carrying objects. We consider the problem of learning commonsense knowledge of when a tool may be useful and how its use may be composed with other tools to accomplish a high-level task instructed by a human. We introduce TANGO, a novel neural model for predicting task-specific tool interactions. TANGO is trained using demonstrations obtained from human teachers instructing a virtual robot in a physics simulator. TANGO encodes the world state consisting of objects and symbolic relationships between them using a graph neural network. The model learns to attend over the scene using knowledge of the goal and the action history, finally decoding the symbolic action to execute. Crucially, we address generalization to unseen environments where some known tools are missing, but alternative unseen tools are present. We show that by augmenting the representation of the environment with pre-trained embeddings derived from a knowledge-base, the model can generalize effectively to novel environments. Experimental results show a 60.5-78.9% improvement over the baseline in predicting successful symbolic plans in unseen settings for a simulated mobile manipulator."
35,The Traveling Tournament Problem with Maximum Tour Length Two: A Practical Algorithm with An Improved  Approximation Bound,Main,"['Planning Algorithms', 'Scheduling', 'Theoretical Foundations of Planning']",https://www.ijcai.org/proceedings/2021/578,"The Traveling Tournament Problem is a well-known benchmark problem in tournament timetabling, which asks us to design a schedule of home/away games of n teams (n is even) under some feasibility requirements such that the total traveling distance of all the n teams is minimized. In this paper, we study TTP-2, the traveling tournament problem where at most two consecutive home games or away games are allowed, and give an effective algorithm for n/2 being odd. Experiments on the well-known benchmark sets show that we can beat previously known solutions for all instances with n/2 being odd by an average improvement of 2.66%. Furthermore, we improve the theoretical approximation ratio from 3/2+O(1/n) to 1+O(1/n) for n/2 being odd, answering a challenging open problem in this area."
36,Non-Parametric Stochastic Sequential Assignment With Random Arrival Times,Main,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2021/579,"We consider a problem wherein jobs arrive at random times and assume random values. Upon each job arrival, the decision-maker must decide immediately whether or not to accept the job and gain the value on offer as a reward, with the constraint that they may only accept at most n jobs over some reference time period. The decision-maker only has access to M independent realisations of the job arrival process. We propose an algorithm, Non-Parametric Sequential Allocation (NPSA), for solving this problem. Moreover, we prove that the expected reward returned by the NPSA algorithm converges in probability to optimality as M grows large. We demonstrate the effectiveness of the algorithm empirically on synthetic data and on public fraud-detection datasets, from where the motivation for this work is derived."
37,Multi-agent Approach to Resource Allocation in Autonomous Vehicle Fleets,Doctoral Consortium,['Planning and Scheduling'],https://www.ijcai.org/proceedings/2021/671,"The development of autonomous vehicles, capable of peer-to-peer communication, as well as the interest in on-demand solutions, are the primary motivations for this study. In the absence of central control, we are interested in forming a fleet of autonomous vehicles capable of responding to city-scale travel demands.  Typically, this problem is solved centrally; this implies that the vehicles have continuous access to a dispatching portal. However, such access to such a global switching infrastructure (for data collection and order delivery) is costly and represents a critical bottleneck. The idea is to use low-cost vehicle-to-vehicle (V2V) communication technologies to coordinate vehicles without a global communication infrastructure. We propose to model the different aspects of decision and optimization problems related to this more general problem. After modeling these problems, the question arises as to the choice of centralized and decentralized solution methods. Methodologically, we explore the directions and compare the performance of distributed constraint optimization techniques (DCOP), self-organized multi-agent techniques, market-based approaches, and centralized operations research solutions."
38,Planning and Reinforcement Learning for General-Purpose Service Robots,Doctoral Consortium,['Robot Planning'],https://www.ijcai.org/proceedings/2021/679,"Despite recent progress in AI and robotics research, especially learned robot skills, there remain significant challenges in building robust, scalable, and general-purpose systems for service robots. This Ph.D. research aims to combine symbolic planning and reinforcement learning to reason about high-level robot tasks and adapt to the real world. We will introduce task planning algorithms that adapt to the environment and other agents, as well as reinforcement learning methods that are practical for service robot systems. Taken together, this work will make a significant step towards creating general-purpose service robots."
39,AI for Planning Public Health Interventions,Doctoral Consortium,"['Planning and Scheduling', 'Markov Decisions Processes']",https://www.ijcai.org/proceedings/2021/682,"Several scenarios involving public health interventions have a unifying underlying theme, that deals with the challenge of optimizing the limited intervention resources available.  My dissertation casts this as a  Restless  Multi-Armed  Bandit  (RMAB) planning problem, identifying and addressing several new, fundamental questions in RMABs."
40,Data Efficient Algorithms and Interpretability Requirements for Personalized Assessment of Taskable AI Systems,Doctoral Consortium,['Model-Based Reasoning'],https://www.ijcai.org/proceedings/2021/693,"The vast diversity of internal designs of black-box AI systems and their nuanced zones of safe functionality make it difficult for a layperson to use them without unintended side effects. The focus of my dissertation is to develop algorithms and requirements of interpretability that would enable a user to assess and understand the limits of an AI system's safe operability. We develop an assessment module that lets an AI system execute high-level instruction sequences in simulators and answer the user queries about its execution of sequences of actions. Our results show that such a primitive query-response capability is sufficient to efficiently derive a user-interpretable model of the system in stationary, fully observable, and deterministic settings."
41,An Automated Framework for Supporting Data-Governance Rule Compliance in Decentralized MIMO Contexts,Doctoral Consortium,['Model-Based Reasoning'],https://www.ijcai.org/proceedings/2021/696,"We propose Dr.Aid, a logic-based AI framework for automated compliance checking of data governance rules over data-flow graphs. The rules are modelled using a formal language based on situation calculus and are suitable for decentralized contexts with multi-input-multi-output (MIMO) processes. Dr.Aid models data rules and flow rules and checks compliance by reasoning about the propagation, combination, modification and application of data rules over the data flow graphs. Our approach is driven and evaluated by real-world datasets using provenance graphs from data-intensive research."
42,Intelligent and Learning Agents: Four Investigations,Early Career,"['Markov Decisions Processes', 'Applications of Planning']",https://www.ijcai.org/proceedings/2021/700,"My research is driven by my curiosity about the nature of intelligence. Of the several aspects that characterise the behaviour of intelligent agents, I primarily study sequential decision making, learning, and exploration. My interests also extend to broader questions on the effects of AI on life and society. In this paper, I present four distinct investigations drawn from my recent work, which range from theoretical to applied, and which involve both analysis and design. I also share my outlook as an early-career researcher."
43,"Width-Based Algorithms for Common Problems in Control, Planning and Reinforcement Learning",Early Career,"['General', 'Planning Algorithms', 'Theoretical Foundations of Planning', 'Applications of Planning']",https://www.ijcai.org/proceedings/2021/702,"Width-based algorithms search for solutions through a general definition of state novelty. These algorithms have been shown to result in state-of-the-art performance in classical planning, and have been successfully applied to model-based and model-free settings where the dynamics of the problem are given through simulation engines. Width-based algorithms performance is understood theoretically through the notion of planning width, providing polynomial guarantees on their runtime and memory consumption. To facilitate synergies across research communities, this paper summarizes the area of width-based planning, and surveys current and future research directions."
44,Connect Multi-Agent Path Finding: Generation and Visualization,Demo,['General'],https://www.ijcai.org/proceedings/2021/714,We present a generic tool to visualize missions of the Connected Multi-Agent Path Finding (CMAPF) problem.  This problem is a variant of MAPF which requires a group of agents to navigate from an initial configuration to a goal configuration while maintaining connection. The user can create an instance of CMAPF and can play the generated plan. Any algorithm for CMAPF can be plugged into the tool.
